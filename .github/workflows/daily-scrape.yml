name: Daily PlanetCinema Scrape

permissions:
  contents: write

# Every 10 minutes
# on:
#   workflow_dispatch: {}
#   schedule:
#     - cron: "*/10 * * * *"

# Every Tuesday at 630pm IL time
# on:
#   workflow_dispatch: {}
#   schedule:
#     # Israel Daylight Time (UTC+3): 18:30 local → 15:30 UTC
#     - cron:  '30 15 * * 2'
#     # Israel Standard Time (UTC+2): 18:30 local → 16:30 UTC
#     - cron:  '30 16 * * 2'

# Once a year
on:
  schedule:
    - cron: '0 0 1 1 *'

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Check out repo
        uses: actions/checkout@v3

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.x"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install selenium webdriver-manager

      - name: Run scraper
        run: python scrape.py

      - name: Commit & push CSV
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add output.csv
          git commit -m "Add daily scrape [skip ci]" || echo "No changes"
          git push
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
